import os
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

import torch
import torch.nn as nn
from torch.utils.data import random_split, Subset
from omegaconf import DictConfig, OmegaConf
from hydra.utils import instantiate
import hydra
import logging
from src.dataset.load_dataset import download_dataset
from src.trainer import Trainer
import os
from torch.optim.lr_scheduler import ReduceLROnPlateau

@hydra.main(config_path="../../conf", config_name="food11_exp1", version_base="1.3")
def main(cfg: DictConfig):
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç –∏ –ª–æ–∞–¥–µ—Ä
    transforms = instantiate(cfg.transforms)
    test_dataset = instantiate(cfg.dataset, mode="test", transforms=transforms.test)
    test_loader = instantiate(cfg.dataloader, dataset=test_dataset, shuffle=False)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model = instantiate(cfg.model)
    model.load_state_dict(torch.load('models/best_model.pth', map_location='cpu'))
    model.eval()

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    
    # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è Trainer
    criterion = torch.nn.CrossEntropyLoss()
    metrics = instantiate(cfg.metrics, device=device)._metrics
    
    # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫–∏ –¥–ª—è –Ω–µ–Ω—É–∂–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    dummy_optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    dummy_train_loader = None  # –ù–µ –Ω—É–∂–µ–Ω –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    dummy_scheduler = None
    
    # –°–æ–∑–¥–∞–µ–º Trainer –¢–û–õ–¨–ö–û –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    trainer = Trainer(
        model=model,
        criterion=criterion,
        device=device,
        metrics=metrics,
    )
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–æ–¥ test –¥–ª—è –æ—Ü–µ–Ω–∫–∏
    test_loss, test_metrics = trainer.test(test_loader)
    
    print("üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏:")
    print(f"Test Loss: {test_loss:.4f}")
    for metric_name, metric_value in test_metrics.items():
        print(f"{metric_name}: {metric_value:.4f}")
    
    return test_loss, test_metrics

if __name__ == "__main__":
    main()