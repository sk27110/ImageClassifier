# ImageClassifier

## Описание

Это небольшой проект, а по совместительству, домашка в курсе по DL, для ознакомления с архитектурами сверточных нейронных сетей и в целом обучением нейросетей. Здесь реализован удобный пайплайн обучения, который не требует переписывания кучи кода для проведения экспериментов. Скорее всего, он же будет использоваться в следующих проектах.

## How to use?

Установка зависимостей
```
pip install -r requiremets.txt

source project_env/bin/activate
```

Далее необходимо настроить Hydra конфиг для обучения и положить его в '/conf'. Пример конфига есть там же.

- Далее для начала обучения:

```
python3 train.py -cn=conf_name
```

- Для промотра графиков tensorboard из корня проекта:

```
tensorboard --logdir=runs
```

- Для теста полученной модели:

```
python3 test.py -cn=conf_name
```

Модель подтягивается из директории, указаной для сохранения лучшей модели.


## Эксперименты и результаты

Для экспериментов был выбран датасет [food11](https://www.kaggle.com/datasets/imbikramsaha/food11). Описание датасета можно посмотреть на kaggle. Он содержит 11 вариантов блюд. Нашей задачей будет попробовать обучить модель для классификации этих изображений.

По хорошему, учитывая ограниченность вычислительных ресурсов и маленький размер датасета, такую задачу нужно решать дообучением уже готовых моделей, таких как EfficientNet, MobileNet V2 или ResNet-ов. Так можно избежать возможного переобучения и убрать проблему нехватки вычислительных ресурсов. Но, так как наш проект учебный, попробуем сделать это с нуля).

Попробуем взять архитектуру, похожую на ResNet-ы. Сделам аналогичный первый сверточный слой. Далее сделаем блоки со Skip-Connection и попробуем, в отличие от ResNet-ов, в каждом блоке сделать по одному сверточному слою каждого размера, чтобы модель быстрее обучалась (src/model/resnet_model.py) Результаты можно найти в experiments/exp1-4.

Лучший результат на тесте:

accuracy: 0.7540 | precision: 0.7566 | recall: 0.7540 | f1: 0.7544

Да, результаты не лучшие, но тем не менее, видно, что модель обучилась.

Судя по всему, прошлую архитектуру вряд-ли получится сильно улучшить. При более слабой регуляризации модель начинает переобучаться, а при более сильной перестает учится или учится медленно.

Попробуем увеличить модель, сделав блоки по два сверточных слоя (src/model/resnet_model_v2). Результаты можно посмотреть в experiments/exp5-7. 

Лучшие результаты на текущий момент:

accuracy: 0.6230 | precision: 0.6384 | recall: 0.6230 | f1: 0.6245

Видно, что модель явно недообучилась. В планах снять сервер на пару суток, чтобы попытаться довести эту модель до ума.


## Итого

Выдающихся результатов достичь не удалось, однако, в процессе работы я позакомился с самим процессом обучения моделей, изучил устройство некоторых архитектур сверточных нейросетей (VGG, ResNet, EfficientNet), научился писать hydra-конфиги, разобрался с логгированием. Для первого опыта работы с нейронками я думаю это неплохо.
